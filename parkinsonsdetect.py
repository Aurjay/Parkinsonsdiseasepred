# -*- coding: utf-8 -*-
"""parkinsonsdetect.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/105xNN-wiDeA5n7fpyg0YVp3bu7BgOn-n
"""

# Parkinsons data is available on https://archive.ics.uci.edu/ml/machine-learning-databases/parkinsons/
#Please use tableau to understand the data better.
#importing the necessary packages
import numpy as np
import pandas as pd
import os, sys
from sklearn.preprocessing import MinMaxScaler
from xgboost import XGBClassifier
from sklearn.model_selection import train_test_split
from sklearn.metrics import accuracy_score
# Reading the csv_file to dataframe
dataframe=pd.read_csv('/content/parkinsons.data')
dataframe.head()
#Assigning features and labels from dataframe
features=dataframe.loc[:,df.columns!='status'].values[:,1:]
labels=dataframe.loc[:,'status'].values
#Printing Number of True and False labels
print("Number of True labels : ",labels[labels==1].shape[0])
print("Number of False labels : ", labels[labels==0].shape[0])
#Scaling the features between -1 and +1 we use MinMax Scaler and fit_transform function 
# to fit and transform the features but not the labels as it is not necessary 
scaler=MinMaxScaler((-1,1))
x=scaler.fit_transform(features)
y=labels
#Assigning variables and splitting the data into train and test data respectively
x_train,x_test,y_train,y_test=train_test_split(x, y, test_size=0.2, random_state=7)
#XGB classifier is initialized here for extreme gradient boosting in order to give one highly probable output.
model=XGBClassifier()
model.fit(x_train,y_train)

#Generating the y_prediction model and calculating accuracy in test data.
y_prediction=model.predict(x_test)
print(accuracy_score(y_test, y_prediction)*100)

